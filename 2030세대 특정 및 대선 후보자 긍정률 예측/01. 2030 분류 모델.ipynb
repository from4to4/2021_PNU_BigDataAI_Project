{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2030 분류 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2030데이터와 언론사 수집 데이터 합치기\n",
    "\n",
    "- Train data\n",
    "    - 4.7 보궐선거 데이터\n",
    "- Test data\n",
    "    - 대선을 위해 수집한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T06:04:03.989805Z",
     "start_time": "2021-05-21T06:04:03.612571Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# 형태소 분류 태그\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T06:04:05.619468Z",
     "start_time": "2021-05-21T06:04:03.991791Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2030 데이터라고 가정한 데이터\n",
    "data2030 = pd.read_csv('data/data_2030_1.csv', index_col=0)\n",
    "\n",
    "# 2030 아닌 데이터\n",
    "data = pd.read_csv('data/재보궐선거댓글데이터_최종_유튜브수정_0429.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T06:04:05.633517Z",
     "start_time": "2021-05-21T06:04:05.620465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           철수야! 뜸 들이지 말고 애국하는 마음으로 물러서라~~~\n",
       "1         박영선은 정동영이 얻은 36프로선에 머무를것. 4.7.이후 OOO정권은 몰락의 길 ...\n",
       "2                             빵선이가서울시장되면서울은공산국가수도제2의평양이될것이다\n",
       "3         서울시장후보더듬당박빵선이는절대로서울시장을할수없다이유는가족은미국.영국에 영주권자이므로...\n",
       "4         부산은오거돈선거이고 오거돈치부선거아닌가 오거돈에 성추해으로 생긴선거가 가독도신공항은...\n",
       "                                ...                        \n",
       "144134    국민의힘 찍지 말라고 이 뉴스가 나온거임\\r\\n내냔에 국민의힘 찍을라 했드만 망했다...\n",
       "144135    굳이 일본과 해저터널 해야되는 이유가 없은이유\\r\\n-일본은고속도로비가 비싸다\\r\\...\n",
       "144136           도랏구나. 열도는 걍 갈라파고스로 남겨 둬라. 재난 난민 넘어 오면 귀찮다.\n",
       "144137                            이걸 왜 하지? 우리한테 아무런 의미가 없는데\n",
       "144138    우리에겐 아무런 도움이 되지 않는 것을 일본에게는 엄청난 기회가 되는 것을 왜 굳이...\n",
       "Name: Comment, Length: 144139, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 댓글을 기반으로 다른 언론사에서 수집한 데이터는 2030 연령이 아니라고 가정\n",
    "data.rename(columns={'댓글':'Comment'}, inplace=True )\n",
    "data['Comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T06:04:05.653463Z",
     "start_time": "2021-05-21T06:04:05.634515Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                내리막이 있으면 다시 오르막이 있는 법, 예방주사라 생각하고 힘들 냅시다.\n",
       "1        2030마음을 얻으려면 조언을 2030을 모셔다가 들어보는 성의를 보여야 됩니다. ...\n",
       "2        전 군대 전역 전까지는 보수를 지지했지만 대학에서 양극화에 관심을 가지면서 진보로 ...\n",
       "3        몸 안에서 무엇인가 무너져 내린 기분..그래도 힘내고 가야죠민주당은 뼈아픈 진단 새...\n",
       "4                                         네 죄송합니다. 삭제하겠습니다\n",
       "                               ...                        \n",
       "48635              간교한 인간성을 가진,  김종인, 안띨수를 섬기느니..  죽는게 났다.\n",
       "48636               이준석 정치연륜이 뭐가있다고 이렇게 나와서 이야기를 많이 하고 다니나\n",
       "48637    준석아 주댕이 조심해라.안철수가 할말이 옳다. 단일화 못햇우면 오세훈 승라없엇다. ...\n",
       "48638                                           김준석  아웃 밉상\n",
       "48639                    토론자가 없어서 양문석, 이준석을 부르냐???한심하네~!!!\n",
       "Name: Comment, Length: 56829, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 댓글을 기반으로 2030 키워드로 유튜브에서 찾아낸 데이터는 2030 데이터라고 가정\n",
    "data2030['Comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T06:04:05.691363Z",
     "start_time": "2021-05-21T06:04:05.654461Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\master4\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>2030</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>철수야! 뜸 들이지 말고 애국하는 마음으로 물러서라~~~</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>박영선은 정동영이 얻은 36프로선에 머무를것. 4.7.이후 OOO정권은 몰락의 길 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>빵선이가서울시장되면서울은공산국가수도제2의평양이될것이다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>서울시장후보더듬당박빵선이는절대로서울시장을할수없다이유는가족은미국.영국에 영주권자이므로...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>부산은오거돈선거이고 오거돈치부선거아닌가 오거돈에 성추해으로 생긴선거가 가독도신공항은...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48635</th>\n",
       "      <td>간교한 인간성을 가진,  김종인, 안띨수를 섬기느니..  죽는게 났다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48636</th>\n",
       "      <td>이준석 정치연륜이 뭐가있다고 이렇게 나와서 이야기를 많이 하고 다니나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48637</th>\n",
       "      <td>준석아 주댕이 조심해라.안철수가 할말이 옳다. 단일화 못햇우면 오세훈 승라없엇다. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48638</th>\n",
       "      <td>김준석  아웃 밉상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48639</th>\n",
       "      <td>토론자가 없어서 양문석, 이준석을 부르냐???한심하네~!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200968 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Comment  2030\n",
       "0                        철수야! 뜸 들이지 말고 애국하는 마음으로 물러서라~~~     0\n",
       "1      박영선은 정동영이 얻은 36프로선에 머무를것. 4.7.이후 OOO정권은 몰락의 길 ...     0\n",
       "2                          빵선이가서울시장되면서울은공산국가수도제2의평양이될것이다     0\n",
       "3      서울시장후보더듬당박빵선이는절대로서울시장을할수없다이유는가족은미국.영국에 영주권자이므로...     0\n",
       "4      부산은오거돈선거이고 오거돈치부선거아닌가 오거돈에 성추해으로 생긴선거가 가독도신공항은...     0\n",
       "...                                                  ...   ...\n",
       "48635            간교한 인간성을 가진,  김종인, 안띨수를 섬기느니..  죽는게 났다.     1\n",
       "48636             이준석 정치연륜이 뭐가있다고 이렇게 나와서 이야기를 많이 하고 다니나     1\n",
       "48637  준석아 주댕이 조심해라.안철수가 할말이 옳다. 단일화 못햇우면 오세훈 승라없엇다. ...     1\n",
       "48638                                         김준석  아웃 밉상     1\n",
       "48639                  토론자가 없어서 양문석, 이준석을 부르냐???한심하네~!!!     1\n",
       "\n",
       "[200968 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 데이터 프레임 만들기\n",
    "df = pd.concat( [pd.DataFrame(data['Comment']), pd.DataFrame(data2030['Comment'])], axis=0 )\n",
    "\n",
    "# 2030이 아니면 0, 2030이면 1으로 라벨링\n",
    "df['2030'] = 0\n",
    "df.iloc[144139:]['2030'] = 1 # 유튜브에서 수집한 2030 키워드 데이터는 2030 세대라고 가정\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T06:04:05.696350Z",
     "start_time": "2021-05-21T06:04:05.692370Z"
    }
   },
   "outputs": [],
   "source": [
    "# 정규식\n",
    "def text_cleaning(text) :\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "    result = hangul.sub('', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T06:04:06.420757Z",
     "start_time": "2021-05-21T06:04:05.698345Z"
    }
   },
   "outputs": [],
   "source": [
    "# 댓글 데이터 한글 정규화 과정\n",
    "df['Comment'] = df['Comment'].apply( lambda x: text_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T06:04:06.427434Z",
     "start_time": "2021-05-21T06:04:06.421765Z"
    }
   },
   "outputs": [],
   "source": [
    "# 형태소 분리 tagger\n",
    "def get_pos(x) :\n",
    "    tagger = Okt() # Okt로 형태소 분리하기\n",
    "    pos = tagger.pos(x) \n",
    "    results = [] # 형태소를 담을 리스트\n",
    "    for i in pos:\n",
    "        if i[1] != 'Josa': # 조사는 빼버리기\n",
    "            results.append(f'{i[0]}/{i[1]}') #'단어/품사'의 형태로 리스트에 추가\n",
    "        else:\n",
    "            pass\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-21T06:04:03.607Z"
    }
   },
   "outputs": [],
   "source": [
    "# 단어당 몇개씩 들어 있는지에 대한 벡터를 생성\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "index_vectorizer = CountVectorizer(tokenizer= lambda x : get_pos(x))\n",
    "X = index_vectorizer.fit_transform(df['Comment'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T05:57:09.188306Z",
     "start_time": "2021-05-21T05:57:09.159254Z"
    }
   },
   "source": [
    "## X-y구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
